# 翻译 http://spark.apache.org/docs/2.4.6/tuning.html#garbage-collection-tuning

```
JVM garbage collection can be a problem when you have large “churn” in terms of the RDDs stored by your program. 
(It is usually not a problem in programs that just read an RDD once and then run many operations on it.) 
When Java needs to evict old objects to make room for new ones, it will need to trace through all your Java objects and find the unused ones.
 The main point to remember here is that the cost of garbage collection is proportional to the number of Java objects,
 so using data structures with fewer objects (e.g. an array of Ints instead of a LinkedList) greatly lowers this cost. 
An even better method is to persist objects in serialized form, as described above: now there will be only one object (a byte array) per RDD partition. 
Before trying other techniques, the first thing to try if GC is a problem is to use serialized caching.

当您在程序存储的RDD方面有较大的“搅动”时，JVM垃圾回收可能会成为问题。 
（在只读取RDD一次然后对其执行许多操作的程序中，这通常不是问题。）
当Java需要驱逐旧对象为新对象腾出空间时，它将需要遍历所有Java对象并查找未使用的。
这里要记住的要点是，垃圾回收的成本与Java对象的数量成正比，
因此，使用对象较少的数据结构（例如，使用Ints数组而不是LinkedList的数据结构）会大大降低此成本。
一种更好的方法是如上所述以序列化形式持久化对象：现在，每个RDD分区只有一个对象（字节数组）。
在尝试其他技术之前，如果GC有问题，首先要尝试使用序列化缓存。

GC can also be a problem due to interference between your tasks’ working memory (the amount of space needed to run the task) and the RDDs cached on your nodes. 
We will discuss how to control the space allocated to the RDD cache to mitigate this.
由于任务的工作内存（运行任务所需的内存空间）与节点上缓存的RDD之间的干扰，GC也会成为问题。
我们将讨论如何控制分配给RDD缓存的空间以减轻这种情况。

Measuring the Impact of GC 衡量GC的影响
The first step in GC tuning is to collect statistics on how frequently garbage collection occurs and the amount of time spent GC. 
This can be done by adding -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps to the Java options.
 (See the configuration guide for info on passing Java options to Spark jobs.)
 Next time your Spark job is run, you will see messages printed in the worker’s logs each time a garbage collection occurs. 
Note these logs will be on your cluster’s worker nodes (in the stdout files in their work directories), not on your driver program.
GC调整的第一步是收集有关垃圾收集发生频率和GC使用时间的统计信息。
这可以通过在Java选项中添加-verbose：gc -XX：+ PrintGCDetails -XX：+ PrintGCTimeStamps来完成。 
（有关将Java选项传递给Spark作业的信息，请参阅配置指南。）
下一次运行Spark作业时，每次发生垃圾收集时，您都会在工作日志中看到打印的消息。
请注意，这些日志将位于群集的工作节点上（位于其工作目录的stdout文件中），而不位于驱动程序上。

Advanced GC Tuning 高级GC调整
To further tune garbage collection, we first need to understand some basic information about memory management in the JVM:
Java Heap space is divided in to two regions Young and Old.
The Young generation is meant to hold short-lived objects while the Old generation is intended for objects with longer lifetimes.

The Young generation is further divided into three regions [Eden, Survivor1, Survivor2].

A simplified description of the garbage collection procedure: 
When Eden is full, a minor GC is run on Eden and objects that are alive from Eden and Survivor1 are copied to Survivor2. 
The Survivor regions are swapped. If an object is old enough or Survivor2 is full, it is moved to Old. Finally, when Old is close to full, a full GC is invoked.
为了进一步调整垃圾回收，我们首先需要了解有关JVM中内存管理的一些基本信息。
Java Heap空间分为Young和Old两个区域。年轻一代用于保存寿命短的对象，而老一代则用于寿命更长的对象
年轻一代又分为三个区域[伊甸园，幸存者1，幸存者2]。
垃圾收集过程的简化描述：当Eden已满时，将在Eden上运行次要GC，并将来自Eden和Survivor1的活动对象复制到Survivor2。
幸存者区域被交换。如果对象足够旧或Survivor2已满，则将其移到“旧”。最后，当Old接近满时，将调用完整的GC。

The goal of GC tuning in Spark is to ensure that only long-lived RDDs are stored in the Old generation and that the Young generation is sufficiently sized to store short-lived objects. 
This will help avoid full GCs to collect temporary objects created during task execution. Some steps which may be useful are

Check if there are too many garbage collections by collecting GC stats. If a full GC is invoked multiple times for before a task completes, it means that there isn’t enough memory available for executing tasks.

If there are too many minor collections but not many major GCs, allocating more memory for Eden would help. You can set the size of the Eden to be an over-estimate of how much memory each task will need. If the size of Eden is determined to be E, then you can set the size of the Young generation using the option -Xmn=4/3*E. (The scaling up by 4/3 is to account for space used by survivor regions as well.)

In the GC stats that are printed, if the OldGen is close to being full, reduce the amount of memory used for caching by lowering spark.memory.fraction; it is better to cache fewer objects than to slow down task execution. Alternatively, consider decreasing the size of the Young generation. This means lowering -Xmn if you’ve set it as above. If not, try changing the value of the JVM’s NewRatio parameter. Many JVMs default this to 2, meaning that the Old generation occupies 2/3 of the heap. It should be large enough such that this fraction exceeds spark.memory.fraction.

Try the G1GC garbage collector with -XX:+UseG1GC. It can improve performance in some situations where garbage collection is a bottleneck. Note that with large executor heap sizes, it may be important to increase the G1 region size with -XX:G1HeapRegionSize

As an example, if your task is reading data from HDFS, the amount of memory used by the task can be estimated using the size of the data block read from HDFS. Note that the size of a decompressed block is often 2 or 3 times the size of the block. So if we wish to have 3 or 4 tasks’ worth of working space, and the HDFS block size is 128 MB, we can estimate size of Eden to be 4*3*128MB.

Monitor how the frequency and time taken by garbage collection changes with the new settings.

在Spark中进行GC调整的目标是确保在旧一代中仅存储长寿命的RDD，而在年轻一代中，其大小足以存储短寿命的对象。这将有助于避免完整的GC收集任务执行期间创建的临时对象。可能有用的一些步骤是
1.通过收集GC统计信息检查是否有太多垃圾回收。如果在任务完成之前多次调用一个完整的GC，则意味着没有足够的内存来执行任务。

2.如果minor GC太多，但major GC却没有很多，那么为Eden分配更多的内存将有所帮助。您可以将Eden的大小设置为每个任务将需要多少内存的高估。
如果确定Eden的大小为E，则可以使用选项-Xmn = 4/3 * E设置Young一代的大小。 （按4/3比例放大也是为了考虑幸存者区域使用的空间。）

3.在打印的GC统计信息中，如果OldGen即将满，请通过降低spark.memory.fraction来减少用于缓存的内存量。最好缓存较少的对象，而不是减慢任务的执行速度。或者，考虑减小Young代的大小。如果您如上所述进行设置，则意味着降低-Xmn。如果不是，请尝试更改JVM的NewRatio参数的值。
许多JVM将此默认值设置为2，这意味着“旧”代占用堆的2/3。它应该足够大，以使该分数超过spark.memory.fraction

4.使用-XX：+ UseG1GC尝试G1GC垃圾收集器。在垃圾收集成为瓶颈的某些情况下，它可以提高性能。请注意，对于较大的执行程序堆大小，使用-XX：G1HeapRegionSize增加G1区域大小可能很重要

例如，如果您的任务是从HDFS读取数据，则可以使用从HDFS读取的数据块的大小来估算任务使用的内存量。
注意，解压缩块的大小通常是块大小的2或3倍。因此，如果我们希望拥有3或4个任务的工作空间，并且HDFS块大小为128 MB，则我们可以估计Eden的大小为4 * 3 * 128MB。
使用新设置监视垃圾回收所花费的频率和时间如何变化。

Our experience suggests that the effect of GC tuning depends on your application and the amount of memory available.
 There are many more tuning options described online, but at a high level, managing how frequently full GC takes place can help in reducing the overhead.

GC tuning flags for executors can be specified by setting spark.executor.extraJavaOptions in a job’s configuration.

我们的经验表明，GC调整的效果取决于您的应用程序和可用内存量。在线上描述了更多的调优选项，但从较高的角度来看，管理完整GC的频率可以帮助减少开销。
可以通过在作业的配置中设置spark.executor.extraJavaOptions来指定执行程序的GC优化标志。












```